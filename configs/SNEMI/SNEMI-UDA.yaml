# All other configurations are set by default. If you want to add new config options,
# please modify ../connectomics/config/defaults.py
SYSTEM:
  NUM_GPUS: 1
  NUM_CPUS: 12

MODEL:
  INPUT_SIZE: [5, 129, 129]
  OUTPUT_SIZE: [5, 129, 129]
  IN_PLANES: 1
  OUT_PLANES: 3
  TARGET_OPT: ["2"]
  LOSS_OPTION: [["WeightedBCEWithLogitsLoss", "DiceLoss"]]
  LOSS_WEIGHT: [[1.0, 0.5]]
  WEIGHT_OPT: [["1", "0"]]
  OUTPUT_ACT: [["none", "sigmoid"]]
  NORM_MODE: "sync_bn"
  UDA: True
  PRE_MODEL_ITER: 0
  
DATASET:
  IMAGE_NAME: 'train-input.h5'
  LABEL_NAME: 'train-labels.h5'
  INPUT_PATH: '/net/cremi/smjoshi/espaces/travail/harvard/dev_pyco/pytorch_connectomics/SNEMI3D/train'
  OUTPUT_PATH: '/net/cremi/smjoshi/espaces/travail/harvard/dev_pyco/pytorch_connectomics/output'
  PAD_SIZE: [4, 64, 64]
  LABEL_EROSION: 1

UDA_DATASET:
  IMAGE_NAME: 'valid_image.h5'
  LABEL_NAME: 'valid_label.h5'
  INPUT_PATH: '/net/cremi/smjoshi/espaces/travail/harvard/dev_pyco/pytorch_connectomics/SNEMI3D/val' # or your own dataset path
  OUTPUT_PATH: '/net/cremi/smjoshi/espaces/travail/harvard/dev_pyco/pytorch_connectomics/output'

SOLVER:
  LR_SCHEDULER_NAME: "WarmupCosineLR"
  BASE_LR: 0.001 # lower LR does not decrease the loss
  ITERATION_STEP: 1
  ITERATION_SAVE: 5000
  ITERATION_TOTAL: 100000
  SAMPLES_PER_BATCH: 4
  
INFERENCE:
  INPUT_SIZE: [5, 129, 129] # Inference stride should be roughly half
  OUTPUT_SIZE: [5, 129, 129] # odd because detectron paper says that better on border with odd values
  OUTPUT_ACT: ["sigmoid"]
  IMAGE_NAME: "valid_image.h5" # or path to your test images
  INPUT_PATH: '/net/cremi/smjoshi/espaces/travail/harvard/dev_pyco/pytorch_connectomics/SNEMI3D/val'
  OUTPUT_PATH: "outputs/SNEMI3D/test"
  OUTPUT_NAME: "result.h5"
  PAD_SIZE: [4, 64, 64]
  AUG_MODE: "min"
  AUG_NUM: 4
  STRIDE: [2, 64, 64]
  SAMPLES_PER_BATCH: 8
